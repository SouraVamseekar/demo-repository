{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "comp-1801-w2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EeDPHq6k3k5X",
        "Ag7m9X30K_B3",
        "VNMxHyMXKsO1"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SouraVamseekar/demo-repository/blob/main/comp_1801_w2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Axrf87838Gv"
      },
      "source": [
        "# Machine learning libraries using Python\n",
        "- COMP 1801 IT lab: 08 Oct 2021 Part 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9mBJRDwyoV2"
      },
      "source": [
        "## Import libraries: Do not forget!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLPQIDZKyhEH"
      },
      "source": [
        "# Import NumPy, which can deal with multi-dimensional arrays such as matrix intuitively.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()  # for plot styling\n",
        "import sklearn.linear_model, sklearn.datasets\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHvvZZRAXJBs"
      },
      "source": [
        "## Vectors: notation and `np.ndarray`.\n",
        "- $\\mathbb{N}$: the set of integers.\n",
        "- $\\mathbb{R}$: the set of real numbers.\n",
        "- $\\mathbb{R}^{m}$: the set of $m$-dimensional real vectors.\n",
        "- Bold lower case (e.g. $\\Vec{v}$): a column vector\n",
        "$$\n",
        "\\Vec{v} \n",
        "= \n",
        "\\begin{bmatrix}\n",
        "v_{0} \\\\\n",
        "v_{1} \\\\\n",
        "\\vdots \\\\\n",
        "v_{m-1} \\\\\n",
        "\\end{bmatrix}\n",
        "\\in \\mathbb{R}^{m}.\n",
        "$$\n",
        "  - We always represent a row vector as the transpose of the column vector, e.g. $\\Vec{v}^{\\top}$.\n",
        "  - A row or column vector (e.g. $\\Vec{v}$ or $\\Vec{v}^{\\top}$) is usually represented by an 1D `np.ndarray` (e.g. `v`) in NumPy.\n",
        "    - Note: an 1D `np.ndarray` does not distinguish row and column vectors. \n",
        "      - To distinguish them (e.g. matrix multiplication), we use an $m \\times 1$ 2D `np.ndarray` (an $m$-dimensional column vector) or $1 \\times n$ 2D `np.ndarray`  (an $n$-dimensional row vector). \n",
        "  - `v.shape`: the shape of `v`. If `v` represents a vector with the size of $m$ ($\\Mat{v} \\in \\mathbb{R}^{m}$), then `v.shape == (m, )`.\n",
        "  - `v[i]`: the `i`-th element of `v`.\n",
        "$$\n",
        "    \\texttt{v} \n",
        "    \\texttt{==}\n",
        "    \\texttt{[v[0], v[1], ..., v[m-1]]} \\\\\n",
        "    =\n",
        "    \\begin{bmatrix}\n",
        "    v_{0} \\\\\n",
        "    v_{1} \\\\\n",
        "    \\vdots \\\\\n",
        "    v_{m-1} \\\\\n",
        "    \\end{bmatrix}\n",
        "    \\in \\mathbb{R}^{m}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1eyXxQSU5cx"
      },
      "source": [
        "### Example of accessing elements of 1D `np.ndarray`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h0_cBjXy72t"
      },
      "source": [
        "v = np.arange(8) ** 2\n",
        "print('v =', v)\n",
        "print('v[0] =', v[0])\n",
        "print('v[1] =', v[1])\n",
        "print('v[4] =', v[4])\n",
        "print('v[7] =', v[7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxA73drs4KiK"
      },
      "source": [
        "## Matrices: notation and `np.ndarray`.\n",
        "- $\\mathbb{R}^{m, n}$: the set of real matrices with the size of $m \\times n$.\n",
        "- Bold upper case (e.g. $\\Mat{A}$): a matrix\n",
        "$$\n",
        "\\Mat{A} \n",
        "= \\begin{bmatrix}\n",
        "a_{0,0} & a_{0,1} & \\cdots & a_{0,n-1} \\\\\n",
        "a_{1,0} & a_{1,1} & \\cdots & a_{1,n-1} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "a_{m-1,0} & a_{m-1,1} & \\cdots & a_{m-1,n-1} \\\\\n",
        "\\end{bmatrix}\n",
        "\\in \\mathbb{R}^{m, n}.\n",
        "$$\n",
        "  - A matrix (e.g. $\\Mat{A}$) is represented by 2D `np.ndarray` (e.g. `A`) in NumPy.\n",
        "  - `A.shape`: the shape of `A`. If `A` represents an $m \\times n$ matrix ($\\Mat{A} \\in \\mathbb{R}^{m, n}$), then `A.shape == (m, n)`.\n",
        "  - $a_{i,j}$ (`A[i, j]`): the element in the $i$-th row and $j$-th column of $\\Mat{A}$ (`A`).\n",
        "  - `A[i, :]`: the 1D `np.ndarray` that contains the $i$-th row of $\\Mat{A}$\\\n",
        "`A[i, :]` $=$ `[A[i, 0], A[i, 1], ..., A[i, n-1]]`\n",
        "$=\n",
        "    \\begin{bmatrix}\n",
        "    a_{i,0} & a_{i,1} & \\cdots & a_{i,n-1} \\\\\n",
        "    \\end{bmatrix}\n",
        "    \\in \\mathbb{R}^{n}.\n",
        "$\n",
        "  - `A[:, j]`: the 1D `np.ndarray` that contains the $j$-th column of $\\Mat{A}$.\\\n",
        "`A[:, j]` $=$ `[A[0, j], A[1, j], ..., A[m-1, j]]`\n",
        "$=\n",
        "    \\begin{bmatrix}\n",
        "    a_{0,j} \\\\ a_{1,j} \\\\ \\vdots \\\\ a_{m-1,j} \\\\\n",
        "    \\end{bmatrix}\n",
        "    \\in \\mathbb{R}^{m}.\n",
        "$\n",
        "  - A 2D `np.ndarray` is the stack of the 1D arrays that correspond to the **row** vectors.\\\n",
        "`A` $=$ `[A[0, :], A[1, :], ..., A[m-1, :]]`\\\n",
        " $=$\\\n",
        "`[[A[0, 0], A[0, 1], ..., A[0, n-1]],`\\\n",
        "&ensp;`[A[1, 0], A[1, 1], ..., A[1, n-1]],`\\\n",
        "&ensp;`...,`\\\n",
        "&ensp;` [A[m-1, 0], A[m-1, 1], ..., A[m-1, n-1]]]`\n",
        "- $\\Mat{A}^{\\top}$ (`A.T`): the transpose of $\\Mat{A}$. If $\\Mat{A} \\in \\mathbb{R}^{m, n}$, then $\\Mat{A}^{\\top} \\in \\mathbb{R}^{n, m}$ (`A.shape == (m, n)` iff `A.T.shape == (n, m)`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_ile5twVIn0"
      },
      "source": [
        "### Example of accessing elements of 2D `np.ndarray`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WUXF-rXzkGA"
      },
      "source": [
        "A = np.arange(20).reshape(4, 5)\n",
        "print('A =\\n', A, '\\n')\n",
        "print('A[2, :] =', A[2, :])\n",
        "print('A[:, 3] =', A[:, 3])\n",
        "print('A[1, 4] =', A[1, 4])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Be7imVmqRO1"
      },
      "source": [
        "## Supervised learning (prediction, e.g. regression and classification)\n",
        "### Overview\n",
        "- What to do: to output ${\\hat{\\Mat{Y}}_\\mathrm{new}}$ as predicted target values for new feature values ${\\Mat{X}_\\mathrm{new}}$.\n",
        "  - Note: if target values are real values, the problem is called a **regression** and if class labels, the problem is called a **classification**.\n",
        "- What we have: the feature and target values${\\Mat{X}_\\mathrm{train}}, {\\Mat{Y}_\\mathrm{train}}$ of the training data.\n",
        "  - Example 1: house price prediction (regression), where each value in $\\Mat{X}$ is the income of an customer and the value in the same row in $\\Mat{Y}$ indicates the customor's house price.\n",
        "  - Example 2: breast cancer prediction (classification), where each values in $\\Mat{X}$ is the area of a tumour and the value in the same row in $\\Mat{Y}$ indicates its label (benign/malignant).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag7m9X30K_B3"
      },
      "source": [
        "### Fit (`obj.fit`): ${\\Mat{X}_\\mathrm{train}}, {\\Mat{Y}_\\mathrm{train}} \\mapsto (\\Vec{\\theta})$.\n",
        "- Inputs: \n",
        "  - ${\\Mat{X}_\\mathrm{train}}$ (`X_train`): the feature matrix, the matrix (2D `np.ndarray`) that contains the feature vectors of the training data. ${\\Mat{X}_\\mathrm{train}} \\in \\mathbb{R}^{m_\\mathrm{train}, n}$ (`X_train.shape == (m_train, n)`).\n",
        "    - $m_\\mathrm{train}$ (`m_train`): the number of the training and data points. $m_\\mathrm{train} \\in \\mathbb{N}$ (`type(m_train) == int`).\n",
        "    - $n$ (`n`): the dimension of a feature vector. $n \\in \\mathbb{N}$ (`type(n) == int`).\n",
        "    - The $i$-th row $\\Vec{x}_\\mathrm{train}^{(i) \\top}$ (`X_train[i, :]`) of the feature matrix ${\\Mat{X}_\\mathrm{train}}$: the feature vector (1D `np.ndarray`) of the $i$-th training data point ($i = 0, 1, \\dots, m_\\mathrm{train}-1$). $\\Vec{x}_\\mathrm{train}^{(i) \\top} \\in \\mathbb{R}^{n}$ (`X_train[i, :].shape == (n, )`).\n",
        "$$\n",
        "        \\Mat{X}_\\mathrm{train}\n",
        "        = \\begin{bmatrix}\n",
        "        \\Vec{x}_\\mathrm{train}^{(0) \\top} \\\\\n",
        "        \\Vec{x}_\\mathrm{train}^{(1) \\top} \\\\\n",
        "        \\vdots \\\\\n",
        "        \\Vec{x}_\\mathrm{train}^{(m_\\mathrm{train} - 1) \\top} \\\\\n",
        "        \\end{bmatrix}\n",
        "        \\in \\mathbb{R}^{m_\\mathrm{train}, n}.\n",
        "$$\n",
        "  - ${\\Mat{Y}_\\mathrm{train}}$ (`y_train` for one-dimensional target cases or `Y_train` for multi-dimensional target cases): the target matrix, the matrix (1D or 2D `np.ndarray`) that contains the target vectors of the training data. ${\\Mat{Y}_\\mathrm{train}} \\in \\mathbb{R}^{m_\\mathrm{train}, p}$ (`y_train.shape == (p, )` or `Y_train.shape == (m_train, p)`).\n",
        "    - $p$ (`p`): the dimension of a target vector. $p \\in \\mathbb{N}$ (`type(p) == int`).\n",
        "    - The $i$-th row $\\Vec{y}_\\mathrm{train}^{(i) \\top}$ (`y_train[i]` or `Y_train[i, :]`) of the target matrix ${\\Mat{Y}_\\mathrm{train}}$: the target vector (`int` or 1D `np.ndarray`) of the $i$-th training data point ($i = 0, 1, \\dots, m_\\mathrm{train}-1$). $\\Vec{y}_\\mathrm{train}^{(i) \\top} \\in \\mathbb{R}^{n}$ (`y_train[i].shape == ()` or `Y_train[i, :].shape == (p, )`).\n",
        "$$\n",
        "        \\Mat{Y}_\\mathrm{train}\n",
        "        = \\begin{bmatrix}\n",
        "        \\Vec{y}_\\mathrm{train}^{(0) \\top} \\\\\n",
        "        \\Vec{y}_\\mathrm{train}^{(1) \\top} \\\\\n",
        "        \\vdots \\\\\n",
        "        \\Vec{y}_\\mathrm{train}^{(m_\\mathrm{train} - 1) \\top} \\\\\n",
        "        \\end{bmatrix}\n",
        "        \\in \\mathbb{R}^{m_\\mathrm{train}, n}.\n",
        "$$\n",
        "- Implicit outputs (attributes to be stored):\n",
        "  - ${\\Vec{\\theta}}$ (e.g. `obj.coeff_`): the parameter vector that specifies a hypothesis (a function $f_{\\Vec{\\theta}}: \\mathbb{R}^{n} \\to \\mathbb{R}^{p}$). ${\\Vec{\\theta}}$ is chosen so that it minimizes the loss function $L(\\Mat{X}_\\mathrm{train}, \\Mat{Y}_\\mathrm{train}; \\Vec{\\theta})$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNMxHyMXKsO1"
      },
      "source": [
        "### Predict (`obj.predict`): ${\\Mat{X}_\\mathrm{new}}(, \\Vec{\\theta}) \\mapsto  {\\hat{\\Mat{Y}}_\\mathrm{new}}$.\n",
        "- Inputs: \n",
        "  - ${\\Mat{X}_\\mathrm{new}}$ (`X_new`): the feature matrix, the matrix (2D `np.ndarray`) that contains the feature vectors of the new data. ${\\Mat{X}_\\mathrm{new}} \\in \\mathbb{R}^{m_\\mathrm{new}, n}$ (`X_new.shape == (m_new, n)`).\n",
        "    - $m_\\mathrm{new}$ (`m_new`): the number of the new and data points. $m_\\mathrm{new} \\in \\mathbb{N}$ (`type(m_new) == int`).\n",
        "    - The $i$-th row $\\Vec{x}_\\mathrm{new}^{(i) \\top}$ (`X_new[i, :]`) of the feature matrix ${\\Mat{X}_\\mathrm{new}}$: the feature vector (1D `np.ndarray`) of the $i$-th new data point ($i = 0, 1, \\dots, m_\\mathrm{new}-1$). $\\Vec{x}_\\mathrm{new}^{(i) \\top} \\in \\mathbb{R}^{n}$ (`X_new[i, :].shape == (n, )`).\n",
        "$$\n",
        "        \\Mat{X}_\\mathrm{new}\n",
        "        = \\begin{bmatrix}\n",
        "        \\Vec{x}_\\mathrm{new}^{(0) \\top} \\\\\n",
        "        \\Vec{x}_\\mathrm{new}^{(1) \\top} \\\\\n",
        "        \\vdots \\\\\n",
        "        \\Vec{x}_\\mathrm{new}^{(m_\\mathrm{new} - 1) \\top} \\\\\n",
        "        \\end{bmatrix}\n",
        "        \\in \\mathbb{R}^{m_\\mathrm{new}, n}.\n",
        "$$\n",
        "- Implicit inputs (attributes to be used):\n",
        "  - ${\\Vec{\\theta}}$ (e.g. `obj.coeff_`): the parameter that specifies a hypothesis (a function $f_{\\Vec{\\theta}}: \\mathbb{R}^{n} \\to \\mathbb{R}^{p}$).\n",
        "\n",
        "- Outputs:\n",
        "  - ${\\hat{\\Mat{Y}}_\\mathrm{new}}$ (`y_pred` for one-dimensional target cases or `Y_pred` for multi-dimensional target cases): the predicted target matrix, the matrix (1D or 2D `np.ndarray`) that contains the predicted values as target vectors for the feature vectors of the new data. ${\\hat{\\Mat{Y}}_\\mathrm{new}} \\in \\mathbb{R}^{m_\\mathrm{new}, p}$ (`y_pred.shape == (p, )` or `Y_pred.shape == (m_new, p)`).\n",
        "    - $p$ (`p`): the dimension of a target vector. $p \\in \\mathbb{N}$ (`type(p) == int`).\n",
        "    - The $i$-th row $\\hat{\\Vec{y}}_\\mathrm{new}^{(i) \\top}$ (`y_pred[i]` or `Y_pred[i, :]`) of ${\\hat{\\Mat{Y}}_\\mathrm{new}}$: \n",
        "    the predicted vector (`int` or 1D `np.ndarray`) as a target vector of the $i$-th new data point ($i = 0, 1, \\dots, m_\\mathrm{new}-1$), given by $\\hat{\\Vec{y}}_\\mathrm{new}^{(i)} = f_\\Vec{\\theta} (\\Vec{x}_\\mathrm{new}^{(i)})$.\n",
        "$$\n",
        "      \\hat{\\Mat{Y}}_\\mathrm{new}\n",
        "      = \\begin{bmatrix}\n",
        "      \\hat{\\Vec{y}}_\\mathrm{new}^{(0) \\top} \\\\\n",
        "      \\hat{\\Vec{y}}_\\mathrm{new}^{(1) \\top} \\\\\n",
        "      \\vdots \\\\\n",
        "      \\hat{\\Vec{y}}_\\mathrm{new}^{(m_\\mathrm{new} - 1) \\top} \\\\\n",
        "      \\end{bmatrix}\n",
        "      = \\begin{bmatrix}\n",
        "      f_\\Vec{\\theta} (\\Vec{x}_\\mathrm{new}^{(0)})^\\top \\\\\n",
        "      f_\\Vec{\\theta} (\\Vec{x}_\\mathrm{new}^{(1)})^\\top \\\\\n",
        "      \\vdots \\\\\n",
        "      f_\\Vec{\\theta} (\\Vec{x}_\\mathrm{new}^{(m_\\mathrm{new} - 1)})^\\top \\\\\n",
        "      \\end{bmatrix}\n",
        "      \\in \\mathbb{R}^{m_\\mathrm{new}, n}.\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mN5gDirOQyD"
      },
      "source": [
        "## Supervised learning example\n",
        "### Load the dataset and show\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc9wZJpc1QHY"
      },
      "source": [
        "# Load the house price dataset\n",
        "house = sklearn.datasets.fetch_california_housing()\n",
        "raw_df = pd.DataFrame(data= np.c_[house['data'], house['target']],\n",
        "                     columns= house['feature_names'] + ['target'])\n",
        "# Shuffle dataset\n",
        "rng = np.random.default_rng(0)\n",
        "df = raw_df.iloc[rng.permutation(len(raw_df))].reset_index(drop=True)\n",
        "\n",
        "# show the data\n",
        "display(df)\n",
        "\n",
        "# Use only one feature\n",
        "col = 'MedInc'\n",
        "\n",
        "# show the data\n",
        "Xy_df = df[[col, 'target']]\n",
        "display(Xy_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwH-jIkBYNeH"
      },
      "source": [
        "Note: `MedInc` is the abbreviation of the median of incomes. We take the median since each row of the dataset correponds to a set of people in a district."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOa3K3lZpZIl"
      },
      "source": [
        "### Convert the data to NumPy ndarrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz9jVwwT2vj1"
      },
      "source": [
        "# prepare NumPy ndarrays\n",
        "X = np.array(df[[col]])\n",
        "y = np.array(df['target'])\n",
        "\n",
        "n_train_points = 50\n",
        "n_new_points = 10\n",
        "\n",
        "# Split the data into training/new data\n",
        "X_train = X[:n_train_points]\n",
        "X_new = X[n_train_points:n_train_points+n_new_points]\n",
        "\n",
        "# Split the targets into training/new data\n",
        "y_train = y[:n_train_points]\n",
        "y_true = y[n_train_points:n_train_points+n_new_points]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCukIcxeYy46"
      },
      "source": [
        "Note: Data splitting will be explained in the 4th week's lecture. It is necessary for a fair evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjzpjRjfp85H"
      },
      "source": [
        "### Fit and predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgc-mSHApWw4"
      },
      "source": [
        "# Create linear regression object\n",
        "obj = sklearn.linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "obj.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "y_pred = obj.predict(X_new)\n",
        "\n",
        "# The parameters\n",
        "theta = obj.coef_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kbkvC8-qz2w"
      },
      "source": [
        "### Plot outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d27VbfALqLO9"
      },
      "source": [
        "# Plot outputs\n",
        "plt.scatter(X_new, y_true,  color='black', label='y_true')\n",
        "plt.scatter(X_new, y_pred, color='blue', label='y_pred')\n",
        "plt.plot(np.r_[0:10:0.1], obj.predict(np.r_[0:10:0.1][:, np.newaxis]), color='blue', label='hypothesis')\n",
        "\n",
        "plt.xlim([0,6])\n",
        "plt.ylim([0,6])\n",
        "\n",
        "plt.xlabel(col)\n",
        "plt.ylabel('house price')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYA2bsE951jQ"
      },
      "source": [
        "### Loss function and score function\n",
        "- Loss: the lower, the better.\n",
        "- Score: the higher, the better. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNVE3JbPqOpO"
      },
      "source": [
        "# The mean squared error loss\n",
        "print('Mean squared error loss: {:.4f}'.format(sklearn.metrics.mean_squared_error(y_true, y_pred)))\n",
        "# The R2 score: 1 is perfect prediction\n",
        "print('R2 score: {:.4f}'.format(sklearn.metrics.r2_score(y_true, y_pred)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7gH7AR1aVsv"
      },
      "source": [
        "Note: the mean square error is affected by the scale of the target values, while R2 score is normalized by the variance of the target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSJzRfXT7bsq"
      },
      "source": [
        "# Plot outputs\n",
        "plt.scatter(X_new, y_true,  color='black', label='y_true')\n",
        "plt.scatter(X_new, y_pred, color='blue', label='y_pred')\n",
        "plt.plot(np.r_[0:10:0.1], obj.predict(np.r_[0:10:0.1][:, np.newaxis]), color='blue', label='hypothesis')\n",
        "\n",
        "plt.xlim([0,6])\n",
        "plt.ylim([0,6])\n",
        "\n",
        "plt.xlabel(col)\n",
        "plt.ylabel('house price')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRUwUUYf9it1"
      },
      "source": [
        "# The mean squared error loss\n",
        "print('Mean squared error loss: {:.4f}'.format(sklearn.metrics.mean_squared_error(y_true, y_pred)))\n",
        "# The R2 score: 1 is perfect prediction\n",
        "print('R2 score: {:.4f}'.format(sklearn.metrics.r2_score(y_true, y_pred)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLOwrGJL6XvO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}